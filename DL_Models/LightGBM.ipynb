{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD+jo2BkfwZixpVjSKNtqv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sameer-Tahir/Project_DS/blob/main/DL_Models/LightGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMtcKVEISDgl",
        "outputId": "6d34c548-30c6-4767-bea3-04db6e251e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Project_DS' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Sameer-Tahir/Project_DS.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install optuna optuna-dashboard\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okZ1JyfISI1W",
        "outputId": "6c5c09a3-8e15-4a3b-b117-f753f807bfeb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting optuna-dashboard\n",
            "  Downloading optuna_dashboard-0.19.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Collecting bottle>=0.13.0 (from optuna-dashboard)\n",
            "  Downloading bottle-0.13.4-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from optuna-dashboard) (1.6.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->optuna-dashboard) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->optuna-dashboard) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->optuna-dashboard) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna_dashboard-0.19.0-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bottle-0.13.4-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: bottle, colorlog, optuna, optuna-dashboard\n",
            "Successfully installed bottle-0.13.4 colorlog-6.9.0 optuna-4.5.0 optuna-dashboard-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd   # data processing\n",
        "import numpy as np    # linear algebra\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import numpy as np, joblib\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from xgboost.callback import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "lOL_akEvSN4L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Load your splits\n",
        "# -----------------------\n",
        "train_df = pd.read_csv(\"dfk1_train.csv\")\n",
        "val_df   = pd.read_csv(\"dfk1_val.csv\")\n",
        "test_df  = pd.read_csv(\"dfk1_test.csv\")"
      ],
      "metadata": {
        "id": "pkDIqtj2SN1t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o dl_preprocessed.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ost_3ltXSNy4",
        "outputId": "f658be72-83fe-408b-adbe-c04735b3afe6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dl_preprocessed.zip\n",
            "  inflating: dl_data_windows.npz     \n",
            "  inflating: label_encoder.pkl       \n",
            "  inflating: scaler.pkl              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load arrays\n",
        "data = np.load(\"dl_data_windows.npz\", allow_pickle=True)\n",
        "X_train, y_train = data[\"X_train\"], data[\"y_train\"]\n",
        "X_val, y_val     = data[\"X_val\"],   data[\"y_val\"]\n",
        "X_test, y_test   = data[\"X_test\"],  data[\"y_test\"]\n",
        "feature_cols     = data[\"feature_cols\"].tolist()\n",
        "classes          = data[\"classes\"]\n",
        "\n",
        "# Load encoder & scaler\n",
        "le = joblib.load(\"label_encoder.pkl\")\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "\n",
        "print(\"✅ Data loaded successfully\")\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Val:\",   X_val.shape, y_val.shape)\n",
        "print(\"Test:\",  X_test.shape, y_test.shape)\n",
        "print(\"Classes:\", classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXNy-lSHSWR9",
        "outputId": "ce45cc91-07e9-444c-d136-0dcef4b54a15"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data loaded successfully\n",
            "Train: (4835, 6, 222) (4835,)\n",
            "Val: (591, 6, 222) (591,)\n",
            "Test: (590, 6, 222) (590,)\n",
            "Classes: ['aggressive-scan' 'cryptojacking' 'icmp-flood' 'icmp-fragmentation'\n",
            " 'icmp-fragmentation_old' 'none' 'os-fingerprinting' 'os-scan' 'port-scan'\n",
            " 'push-ack-flood' 'serice-detection' 'service-detection' 'syn-flood'\n",
            " 'syn-stealth' 'synonymous-ip-flood' 'tcp-flood' 'udp-flood' 'vuln-scan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Flatten raw\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_val_flat = X_val.reshape(X_val.shape[0], -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# ================================================================\n",
        "# LightGBM with Feature Selection + SHAP\n",
        "# ================================================================\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "import shap\n",
        "\n",
        "# -----------------------\n",
        "# Feature Selection (XGBoost-based)\n",
        "# -----------------------\n",
        "print(\"🔍 Running feature selection...\")\n",
        "xgb_fs = xgb.XGBClassifier(\n",
        "    n_estimators=200, max_depth=6, learning_rate=0.05,\n",
        "    subsample=0.8, colsample_bytree=0.8, tree_method=\"hist\"\n",
        ")\n",
        "xgb_fs.fit(X_train_flat, y_train)\n",
        "\n",
        "selector = SelectFromModel(xgb_fs, prefit=True, threshold=\"median\")  # keep top 50% features\n",
        "X_train_sel = selector.transform(X_train_flat)\n",
        "X_val_sel = selector.transform(X_val_flat)\n",
        "X_test_sel = selector.transform(X_test_flat)\n",
        "\n",
        "print(f\"✅ Reduced features: {X_train_sel.shape[1]} (from {X_train_flat.shape[1]})\")\n",
        "\n",
        "# -----------------------\n",
        "# LightGBM Training\n",
        "# -----------------------\n",
        "lgb_model = lgb.LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1,\n",
        "    num_leaves=64,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective=\"multiclass\",\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lgb_model.fit(\n",
        "    X_train_sel, y_train,\n",
        "    eval_set=[(X_val_sel, y_val)],\n",
        "    eval_metric=\"multi_logloss\"\n",
        ")\n",
        "\n",
        "# -----------------------\n",
        "# Predictions & Metrics\n",
        "# -----------------------\n",
        "y_pred_lgb = lgb_model.predict(X_test_sel)\n",
        "\n",
        "acc_lgb = accuracy_score(y_test, y_pred_lgb)\n",
        "f1_lgb = f1_score(y_test, y_pred_lgb, average=\"macro\")\n",
        "report_lgb = classification_report(y_test, y_pred_lgb, target_names=classes, zero_division=0)\n",
        "cm_lgb = confusion_matrix(y_test, y_pred_lgb)\n",
        "\n",
        "print(\"\\n✅ LightGBM Results (with Feature Selection)\")\n",
        "print(\"Accuracy:\", acc_lgb)\n",
        "print(\"Macro-F1:\", f1_lgb)\n",
        "print(report_lgb)\n",
        "\n",
        "# -----------------------\n",
        "# Confusion Matrix\n",
        "# -----------------------\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(cm_lgb, cmap=\"Greens\")\n",
        "plt.title(\"LightGBM Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "plt.xticks(np.arange(len(classes)), classes, rotation=90)\n",
        "plt.yticks(np.arange(len(classes)), classes)\n",
        "for i in range(cm_lgb.shape[0]):\n",
        "    for j in range(cm_lgb.shape[1]):\n",
        "        plt.text(j, i, cm_lgb[i, j], ha=\"center\", va=\"center\",\n",
        "                 color=\"red\" if cm_lgb[i, j] > cm_lgb.max()/2 else \"black\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"LightGBM_confusion_matrix.png\")\n",
        "plt.show()\n",
        "\n",
        "# -----------------------\n",
        "# Per-Class F1\n",
        "# -----------------------\n",
        "prec, rec, f1, support = precision_recall_fscore_support(y_test, y_pred_lgb, zero_division=0)\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.bar(classes, f1, color=\"green\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Per-Class F1 Scores (LightGBM)\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"LightGBM_f1_per_class.png\")\n",
        "plt.show()\n",
        "\n",
        "# -----------------------\n",
        "# Feature Importance\n",
        "# -----------------------\n",
        "lgb.plot_importance(lgb_model, max_num_features=20, importance_type=\"gain\")\n",
        "plt.title(\"LightGBM Feature Importance (Top 20)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"LightGBM_feature_importance.png\")\n",
        "plt.show()\n",
        "\n",
        "# -----------------------\n",
        "# SHAP Explainability\n",
        "# -----------------------\n",
        "print(\"🔍 Generating SHAP values (may take some time)...\")\n",
        "explainer = shap.TreeExplainer(lgb_model)\n",
        "shap_values = explainer.shap_values(X_test_sel[:200])  # limit for speed\n",
        "\n",
        "shap.summary_plot(shap_values, X_test_sel[:200], feature_names=[f\"f{i}\" for i in range(X_test_sel.shape[1])])\n",
        "plt.savefig(\"LightGBM_shap_summary.png\", bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# -----------------------\n",
        "# Save Results\n",
        "# -----------------------\n",
        "results_lgb = {\n",
        "    \"accuracy\": float(acc_lgb),\n",
        "    \"macro_f1\": float(f1_lgb),\n",
        "    \"report\": report_lgb,\n",
        "    \"confusion_matrix\": cm_lgb.tolist()\n",
        "}\n",
        "with open(\"results_lightgbm.json\", \"w\") as f:\n",
        "    json.dump(results_lgb, f, indent=4)\n",
        "\n",
        "print(\"📂 Saved: results_lightgbm.json and plots (Confusion, F1, Feature Importance, SHAP)\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2KIsGo1SWPN",
        "outputId": "7cb6dadf-c665-4930-a7b1-018831ef189f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Running feature selection...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A-LxKpFxSYto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B9uegotgSYql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XoLgFjsZSNvl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}